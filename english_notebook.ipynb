{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# from utils import preprocess, train_test_split_data\n",
    "from importlib import reload\n",
    "import os\n",
    "import utils\n",
    "utils = reload(utils)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 1: Data preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# import nltk, nltk.data\n",
    "\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "# with open('data/alice_in_wonderland.txt') as f:\n",
    "#     text = f.read()\n",
    "#     print('\\n-----\\n'.join(tokenizer.tokenize(text)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# sentencepiece package look for sentence hence linebreak needs to be preserved\n",
    "\n",
    "with open('data/alice_in_wonderland.txt') as f:\n",
    "    text = f.read()\n",
    "    prepro_text = utils.preprocess(text) # preprocessing text\n",
    "    train, test = utils.train_test_split_data(prepro_text, test_size=0.2) # split the data\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# saving the splitted corpus\n",
    "with open('eng_text/train_eng.txt', 'w') as f:\n",
    "    # f.write(str(train))\n",
    "    f.write('\\n'.join(train))\n",
    "\n",
    "with open('eng_text/test_eng.txt', 'w') as f:\n",
    "    # f.write(str(test)) \n",
    "    f.write('\\n'.join(test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comments/ideas\n",
    "* split is not randomized\n",
    "* more steps like lemmatization/stemming can be added in prepro\n",
    "* there is not much preprocessing needs to be done\n",
    "* may be some special characters/ punctuation can be removed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2: Subword Segmentation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Granularity: characters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# training model\n",
    "\n",
    "## CHANGE PATH TO SHIFT .model & .vocab in models/sentencepiece\n",
    "\n",
    "# total 72 different types of characters\n",
    "# coverage changes for non-english\n",
    "\n",
    "n_ch = 72\n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_train \\\n",
    "  --input='../../eng_text/train_eng.txt' \\\n",
    "  --model_prefix=en_s1_train \\\n",
    "  --vocab_size=$n_ch \\\n",
    "  --character_coverage=1.0 \\\n",
    "  --model_type=bpe\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../../eng_text/train_eng.txt\n",
      "  input_format: \n",
      "  model_prefix: en_s1_train\n",
      "  model_type: BPE\n",
      "  vocab_size: 95\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ../../eng_text/train_eng.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 2816 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=114468\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=69\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 2816 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 2816\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 4521\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3172 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=619 size=20 all=1257 active=1188 piece=▁c\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: en_s1_train.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en_s1_train.vocab\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# segment the text (original)\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_encode \\\n",
    "  --model=en_s1_train.model \\\n",
    "  --output_format=piece \\\n",
    "  < '../../eng_text/train_eng.txt' \\\n",
    "  > '../../eng_text/en_s1_train.txt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# training model - test set\n",
    "\n",
    "## CHANGE PATH TO SHIFT .model & .vocab in models/sentencepiece\n",
    "\n",
    "# total 72 different types of characters\n",
    "# coverage changes for non-english\n",
    "\n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_train \\\n",
    "  --input='../../eng_text/test_eng.txt' \\\n",
    "  --model_prefix=en_s1_test \\\n",
    "  --vocab_size=$n_ch \\\n",
    "  --character_coverage=1.0 \\\n",
    "  --model_type=bpe\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../../eng_text/test_eng.txt\n",
      "  input_format: \n",
      "  model_prefix: en_s1_test\n",
      "  model_type: BPE\n",
      "  vocab_size: 95\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ../../eng_text/test_eng.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 680 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=28059\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=67\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 680 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 680\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 1709\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=841 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=147 size=20 all=1021 active=954 piece=▁of\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: en_s1_test.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en_s1_test.vocab\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# segment the text (original) - test set\n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_encode \\\n",
    "  --model=en_s1_test.model \\\n",
    "  --output_format=piece \\\n",
    "  < '../../eng_text/test_eng.txt' \\\n",
    "  > '../../eng_text/en_s1_test.txt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Granularity: subword units (smaller vocabulary)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# training model\n",
    "\n",
    "# coverage changes for non-english\n",
    "# fine-tune vocab_size in range of 100-800 for best performance\n",
    "\n",
    "small_vocab = 450\n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_train \\\n",
    "  --input='../../eng_text/train_eng.txt' \\\n",
    "  --model_prefix=en_s2_train \\\n",
    "  --vocab_size=$small_vocab \\\n",
    "  --character_coverage=1.0 \\\n",
    "  --model_type=bpe\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../../eng_text/train_eng.txt\n",
      "  input_format: \n",
      "  model_prefix: en_s2_train\n",
      "  model_type: BPE\n",
      "  vocab_size: 450\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ../../eng_text/train_eng.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 2816 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=114468\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=69\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 2816 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 2816\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 4521\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3172 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=619 size=20 all=1257 active=1188 piece=▁c\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=421 size=40 all=1590 active=1521 piece=ar\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=318 size=60 all=1909 active=1840 piece=▁was\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=213 size=80 all=2165 active=2096 piece=▁T\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=153 size=100 all=2458 active=2389 piece=▁an\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=150 min_freq=7\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=116 size=120 all=2631 active=1166 piece=▁D\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=98 size=140 all=2821 active=1356 piece=ge\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=85 size=160 all=3030 active=1565 piece=▁ag\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=76 size=180 all=3165 active=1700 piece=een\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=66 size=200 all=3228 active=1763 piece=▁then\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=65 min_freq=7\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=59 size=220 all=3356 active=1129 piece=▁into\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=52 size=240 all=3447 active=1220 piece=▁its\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=47 size=260 all=3572 active=1345 piece=▁your\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=42 size=280 all=3693 active=1466 piece=▁(\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=39 size=300 all=3782 active=1555 piece=▁how\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=39 min_freq=6\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=36 size=320 all=3865 active=1081 piece=▁such\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=34 size=340 all=3931 active=1147 piece=phon\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32 size=360 all=3975 active=1191 piece=ever\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: en_s2_train.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en_s2_train.vocab\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# segment the text (original) -train\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_encode \\\n",
    "  --model=en_s2_train.model \\\n",
    "  --output_format=piece \\\n",
    "  < '../../eng_text/train_eng.txt' \\\n",
    "  > '../../eng_text/en_s2_train.txt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# training model - test set\n",
    "\n",
    "# coverage changes for non-english\n",
    "# fine-tune vocab_size in range of 100-800 for best performance\n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_train \\\n",
    "  --input='../../eng_text/test_eng.txt' \\\n",
    "  --model_prefix=en_s2_test \\\n",
    "  --vocab_size=$small_vocab \\\n",
    "  --character_coverage=1.0 \\\n",
    "  --model_type=bpe\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../../eng_text/test_eng.txt\n",
      "  input_format: \n",
      "  model_prefix: en_s2_test\n",
      "  model_type: BPE\n",
      "  vocab_size: 450\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ../../eng_text/test_eng.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 680 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=28059\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=67\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 680 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 680\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 1709\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=841 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=147 size=20 all=1021 active=954 piece=▁of\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=92 size=40 all=1271 active=1204 piece=▁ha\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=70 size=60 all=1495 active=1428 piece=▁she\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=54 size=80 all=1669 active=1602 piece=▁Alice\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=38 size=100 all=1796 active=1729 piece=gh\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=38 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32 size=120 all=1958 active=1157 piece=▁wh\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25 size=140 all=2050 active=1249 piece=and\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22 size=160 all=2131 active=1330 piece=▁look\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19 size=180 all=2179 active=1378 piece=▁Queen\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17 size=200 all=2238 active=1437 piece=imp\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=17 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16 size=220 all=2276 active=1030 piece=▁their\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14 size=240 all=2341 active=1095 piece=ouse\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13 size=260 all=2397 active=1151 piece=ting\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=280 all=2456 active=1210 piece=ning\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=300 all=2536 active=1290 piece=oup\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=320 all=2564 active=1028 piece=▁O\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=340 all=2604 active=1068 piece=▁witness\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=360 all=2635 active=1099 piece=right\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=380 all=2654 active=1118 piece=▁gu\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: en_s2_test.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en_s2_test.vocab\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# segment the text (original)\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_encode \\\n",
    "  --model=en_s2_test.model \\\n",
    "  --output_format=piece \\\n",
    "  < '../../eng_text/test_eng.txt' \\\n",
    "  > '../../eng_text/en_s2_test.txt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Granularity: subword units (larger vocabulary)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# training model\n",
    "\n",
    "# coverage changes for non-english\n",
    "# fine-tune vocab_size in range of 1500-3000 for best performance\n",
    "# training model\n",
    "\n",
    "# coverage changes for non-english\n",
    "# fine-tune vocab_size in range of 100-800 for best performance\n",
    "\n",
    "large_vocab = 2000\n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_train \\\n",
    "  --input='../../eng_text/train_eng.txt' \\\n",
    "  --model_prefix=en_s3_train \\\n",
    "  --vocab_size=$large_vocab \\\n",
    "  --character_coverage=1.0 \\\n",
    "  --model_type=bpe\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../../eng_text/train_eng.txt\n",
      "  input_format: \n",
      "  model_prefix: en_s3_train\n",
      "  model_type: BPE\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ../../eng_text/train_eng.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 2816 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=114468\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=69\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 2816 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 2816\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 4521\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3172 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=619 size=20 all=1257 active=1188 piece=▁c\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=421 size=40 all=1590 active=1521 piece=ar\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=318 size=60 all=1909 active=1840 piece=▁was\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=213 size=80 all=2165 active=2096 piece=▁T\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=153 size=100 all=2458 active=2389 piece=▁an\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=150 min_freq=7\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=116 size=120 all=2631 active=1166 piece=▁D\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=98 size=140 all=2821 active=1356 piece=ge\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=85 size=160 all=3030 active=1565 piece=▁ag\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=76 size=180 all=3165 active=1700 piece=een\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=66 size=200 all=3228 active=1763 piece=▁then\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=65 min_freq=7\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=59 size=220 all=3356 active=1129 piece=▁into\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=52 size=240 all=3447 active=1220 piece=▁its\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=47 size=260 all=3572 active=1345 piece=▁your\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=42 size=280 all=3693 active=1466 piece=▁(\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=39 size=300 all=3782 active=1555 piece=▁how\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=39 min_freq=6\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=36 size=320 all=3865 active=1081 piece=▁such\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=34 size=340 all=3931 active=1147 piece=phon\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32 size=360 all=3975 active=1191 piece=ever\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=30 size=380 all=4103 active=1319 piece=▁cat\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28 size=400 all=4211 active=1427 piece=▁ey\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=28 min_freq=6\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=27 size=420 all=4239 active=1027 piece=▁March\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25 size=440 all=4290 active=1078 piece=▁won\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24 size=460 all=4353 active=1141 piece=▁every\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22 size=480 all=4393 active=1181 piece=ild\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21 size=500 all=4426 active=1214 piece=de\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=21 min_freq=5\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21 size=520 all=4492 active=1063 piece=▁upon\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20 size=540 all=4526 active=1097 piece=▁rather\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18 size=560 all=4564 active=1135 piece=▁Y\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17 size=580 all=4596 active=1167 piece=▁V\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16 size=600 all=4646 active=1217 piece=ity\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=16 min_freq=4\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16 size=620 all=4692 active=1042 piece=▁something\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15 size=640 all=4760 active=1110 piece=▁mean\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14 size=660 all=4815 active=1165 piece=▁TH\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14 size=680 all=4830 active=1180 piece=ertain\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13 size=700 all=4858 active=1208 piece=odo\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=13 min_freq=4\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13 size=720 all=4874 active=1016 piece=▁both\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=740 all=4884 active=1026 piece=ige\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=760 all=4915 active=1057 piece=▁baby\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=780 all=4921 active=1063 piece=dv\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=800 all=4988 active=1130 piece=owed\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11 min_freq=4\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=820 all=5010 active=1020 piece=▁mouth\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=840 all=5001 active=1011 piece=you\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=860 all=5030 active=1040 piece=▁cont\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=880 all=5036 active=1046 piece=▁bottle\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=900 all=5050 active=1060 piece=eer\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=920 all=5089 active=1039 piece=▁key\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=940 all=5093 active=1043 piece=▁least\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=960 all=5085 active=1035 piece=▁serpent\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=980 all=5099 active=1049 piece=Who\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1000 all=5156 active=1106 piece=▁che\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1020 all=5175 active=1014 piece=▁foll\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1040 all=5169 active=1008 piece=▁forgot\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1060 all=5154 active=993 piece=▁direction\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1080 all=5203 active=1042 piece=iol\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1100 all=5258 active=1097 piece=ssed\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1120 all=5270 active=1009 piece=▁dist\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1140 all=5270 active=1009 piece=▁puppy\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1160 all=5259 active=998 piece=▁though\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=1180 all=5258 active=997 piece=▁'\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=1200 all=5299 active=1038 piece=▁oh\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=1220 all=5323 active=1025 piece=time\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=1240 all=5344 active=1046 piece=ather\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=1260 all=5349 active=1051 piece=▁scre\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=1280 all=5347 active=1049 piece=▁inches\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=1300 all=5332 active=1034 piece=▁distance\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1320 all=5345 active=1014 piece=wh\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1340 all=5381 active=1050 piece=▁On\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1360 all=5395 active=1064 piece=▁inv\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1380 all=5402 active=1071 piece=rying\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1400 all=5397 active=1066 piece=▁love\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=5 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1420 all=5395 active=997 piece=▁knock\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1440 all=5386 active=988 piece=▁nearer\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1460 all=5376 active=978 piece=▁twinkle\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1480 all=5365 active=967 piece=He\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1500 all=5402 active=1004 piece=She\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1520 all=5434 active=1033 piece=tom\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1540 all=5455 active=1054 piece=hand\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1560 all=5471 active=1070 piece=▁ARE\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1580 all=5478 active=1077 piece=▁sig\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1600 all=5491 active=1090 piece=times\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1620 all=5491 active=1000 piece=▁mice\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1640 all=5491 active=1000 piece=ssible\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1660 all=5478 active=987 piece=▁often\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1680 all=5471 active=980 piece=▁corner\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1700 all=5464 active=973 piece=▁sleepy\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1720 all=5448 active=985 piece=▁sounded\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1740 all=5435 active=972 piece=▁instantly\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1760 all=5435 active=972 piece=Su\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1780 all=5462 active=999 piece=cho\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1800 all=5494 active=1031 piece=▁HE\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1820 all=5502 active=1009 piece=gled\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1840 all=5516 active=1023 piece=▁Eag\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1860 all=5516 active=1023 piece=▁per\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1880 all=5521 active=1028 piece=nging\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1900 all=5517 active=1024 piece=▁days\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1920 all=5513 active=997 piece=▁pick\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: en_s3_train.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en_s3_train.vocab\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# segment the text (original)\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_encode \\\n",
    "  --model=en_s3_train.model \\\n",
    "  --output_format=piece \\\n",
    "  < '../../eng_text/train_eng.txt' \\\n",
    "  > '../../eng_text/en_s3_train.txt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# training model - test set\n",
    "\n",
    "# coverage changes for non-english\n",
    "# fine-tune vocab_size in range of 1500-3000 for best performance\n",
    "# training model\n",
    "\n",
    "# coverage changes for non-english\n",
    "# fine-tune vocab_size in range of 100-800 for best performance\n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_train \\\n",
    "  --input='../../eng_text/test_eng.txt' \\\n",
    "  --model_prefix=en_s3_test \\\n",
    "  --vocab_size=$large_vocab \\\n",
    "  --character_coverage=1.0 \\\n",
    "  --model_type=bpe\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../../eng_text/test_eng.txt\n",
      "  input_format: \n",
      "  model_prefix: en_s3_test\n",
      "  model_type: BPE\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ../../eng_text/test_eng.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 680 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=28059\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=67\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 680 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 680\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 1709\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=841 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=147 size=20 all=1021 active=954 piece=▁of\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=92 size=40 all=1271 active=1204 piece=▁ha\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=70 size=60 all=1495 active=1428 piece=▁she\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=54 size=80 all=1669 active=1602 piece=▁Alice\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=38 size=100 all=1796 active=1729 piece=gh\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=38 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32 size=120 all=1958 active=1157 piece=▁wh\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25 size=140 all=2050 active=1249 piece=and\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22 size=160 all=2131 active=1330 piece=▁look\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19 size=180 all=2179 active=1378 piece=▁Queen\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17 size=200 all=2238 active=1437 piece=imp\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=17 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16 size=220 all=2276 active=1030 piece=▁their\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14 size=240 all=2341 active=1095 piece=ouse\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13 size=260 all=2397 active=1151 piece=ting\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=280 all=2456 active=1210 piece=ning\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=300 all=2536 active=1290 piece=oup\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=320 all=2564 active=1028 piece=▁O\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=340 all=2604 active=1068 piece=▁witness\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=360 all=2635 active=1099 piece=right\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=380 all=2654 active=1118 piece=▁gu\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=400 all=2653 active=1117 piece=ER\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=420 all=2711 active=1053 piece=▁cur\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=440 all=2719 active=1061 piece=ak\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=460 all=2775 active=1117 piece=▁ch\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=480 all=2793 active=1135 piece=▁way\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=500 all=2789 active=1131 piece=▁which\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=520 all=2820 active=1032 piece=ate\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=540 all=2855 active=1067 piece=ever\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=560 all=2869 active=1081 piece=▁knew\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=580 all=2857 active=1069 piece=▁Lizard\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=600 all=2862 active=1074 piece=ead\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=620 all=2905 active=1041 piece=Well\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=640 all=2926 active=1062 piece=▁its\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=660 all=2930 active=1066 piece=▁face\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=680 all=2923 active=1059 piece=▁found\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=700 all=2915 active=1051 piece=▁turning\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=720 all=2909 active=995 piece=cl\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=740 all=2936 active=1022 piece=een\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=760 all=2958 active=1044 piece=ure\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=780 all=2971 active=1057 piece=aper\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=800 all=2993 active=1079 piece=upid\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=820 all=2997 active=1003 piece=There\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=840 all=2997 active=1003 piece=▁dist\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=860 all=2987 active=993 piece=▁talk\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=880 all=2983 active=989 piece=▁slate\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=900 all=2975 active=981 piece=▁simple\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=920 all=2957 active=983 piece=▁executed\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=940 all=2947 active=973 piece=PT\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=960 all=2972 active=998 piece=And\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=980 all=2982 active=1008 piece=eak\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1000 all=3009 active=1035 piece=til\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1020 all=3012 active=1002 piece=Cons\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1040 all=3021 active=1011 piece=orth\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1060 all=3017 active=1007 piece=▁car\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1080 all=3022 active=1012 piece=▁sit\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1100 all=3023 active=1013 piece=other\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1120 all=3017 active=994 piece=▁deny\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1140 all=3008 active=985 piece=▁mark\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1160 all=2996 active=973 piece=▁want\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1180 all=2986 active=963 piece=▁doesn\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1200 all=2977 active=954 piece=▁these\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1220 all=2963 active=987 piece=▁garden\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1240 all=2947 active=971 piece=Consider\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1260 all=2927 active=951 piece=▁through\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1280 all=2910 active=934 piece=▁important\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1300 all=2891 active=915 piece=.]\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1320 all=2894 active=1004 piece=OI\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1340 all=2900 active=1010 piece=ls\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1360 all=2895 active=1005 piece=ARD\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1380 all=2891 active=1001 piece=ROM\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1400 all=2885 active=995 piece=arm\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1420 all=2887 active=1003 piece=els\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1440 all=2895 active=1011 piece=isk\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1460 all=2902 active=1018 piece=oun\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1480 all=2910 active=1026 piece=vol\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1500 all=2901 active=1017 piece=▁QU\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1 min_freq=0\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1520 all=2900 active=999 piece=Coll\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1540 all=2894 active=993 piece=VERY\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1560 all=2893 active=992 piece=cove\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1580 all=2901 active=1000 piece=ieth\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1600 all=2899 active=998 piece=orty\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1 min_freq=0\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1620 all=2897 active=998 piece=urry\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1640 all=2884 active=985 piece=▁PRO\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1660 all=2868 active=969 piece=▁emp\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1680 all=2863 active=964 piece=▁our\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1700 all=2851 active=952 piece=Shall\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1 min_freq=0\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1720 all=2845 active=995 piece=apers\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1740 all=2846 active=996 piece=essed\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1760 all=2846 active=996 piece=onest\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1780 all=2846 active=996 piece=▁Betw\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1800 all=2828 active=978 piece=▁Turn\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1 min_freq=0\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1820 all=2815 active=988 piece=▁days\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1840 all=2798 active=971 piece=▁here\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1860 all=2784 active=957 piece=▁ripp\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1880 all=2770 active=943 piece=▁than\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1900 all=2754 active=927 piece=Behead\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1 min_freq=0\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1920 all=2742 active=989 piece=eaking\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: en_s3_test.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en_s3_test.vocab\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# segment the text (original)\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_encode \\\n",
    "  --model=en_s3_test.model \\\n",
    "  --output_format=piece \\\n",
    "  < '../../eng_text/test_eng.txt' \\\n",
    "  > '../../eng_text/en_s3_test.txt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Observation\n",
    "* Character - Almost every single character is segmented\n",
    "* Subword unit (smaller vacob) - The length of segmented subword is longer and many words are also considered as subwords\n",
    "* Subword unit (larger vocab) - Here, subwords are longer. Many words are themself segmented into single subwords. It can also be seen consistently that orignally longer words are broken into two or more segments.  \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 3: LM Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Training baseline LM (eng_s1)\n",
    "\n",
    "# At what setting of rnnlm, we need the get the PP of baseline? \n",
    "# what is the use of class size\n",
    "\n",
    "!cd models/rnnlm \\\n",
    "    && ../../rnnlm/rnnlm \\\n",
    "    -train '../../eng_text/en_s1_train.txt' \\\n",
    "    -valid '../../eng_text/en_s1_test.txt' \\\n",
    "    -rnnlm en_s1 \\\n",
    "      -hidden 40 \\\n",
    "      -rand-seed 1 \\\n",
    "      -debug 2 \\\n",
    "      -bptt 3 \\\n",
    "      -class $n_ch"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "debug mode: 2\n",
      "train file: ../../eng_text/en_s1_train.txt\n",
      "valid file: ../../eng_text/en_s1_test.txt\n",
      "class size: 95\n",
      "Hidden layer size: 40\n",
      "BPTT: 3\n",
      "Rand seed: 1\n",
      "rnnlm file: en_s1\n",
      "Starting training using file ../../eng_text/en_s1_train.txt\n",
      "Restoring network from file to continue training...\n",
      "WARNING: number of classes exceeds vocabulary size!\n",
      "Iter:   3\tAlpha: 0.025000\t   TRAIN entropy: 4.9836    Words/sec: 88832.1   VALID entropy: 3.8072\n",
      "Iter:   4\tAlpha: 0.012500\t   TRAIN entropy: 3.2937    Words/sec: 90785.7   VALID entropy: 3.7471\n",
      "Iter:   5\tAlpha: 0.006250\t   TRAIN entropy: 3.2628    Words/sec: 112106.8   VALID entropy: 3.7099\n",
      "Iter:   6\tAlpha: 0.003125\t   TRAIN entropy: 3.2470    Words/sec: 98864.9   VALID entropy: 3.6900\n",
      "Iter:   7\tAlpha: 0.001563\t   TRAIN entropy: 3.2386    Words/sec: 97880.2   VALID entropy: 3.6813\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Training LM on subword units (smaller vocab - eng_s2)\n",
    "\n",
    "# At what setting of rnnlm, we need the get the PP of baseline? \n",
    "# what is the use of class size\n",
    "# How to increase no. of iterations?\n",
    "\n",
    "#incr hidden -> better pp\n",
    "#incr bptt -> worse pp\n",
    "# if class < vocabsize -> worse pp\n",
    "#incr class -> better pp\n",
    "\n",
    "## May be need to simplify the corpus (in preprocessing)\n",
    "\n",
    "      # -bptt-block 1 \\\n",
    "!cd models/rnnlm/ \\\n",
    "    && ../../rnnlm/rnnlm \\\n",
    "    -train '../../eng_text/en_s2_train.txt' \\\n",
    "    -valid '../../eng_text/en_s2_test.txt' \\\n",
    "    -rnnlm en_s2 \\\n",
    "      -hidden 100 \\\n",
    "      -rand-seed 1 \\\n",
    "      -debug 2 \\\n",
    "      -bptt 0 \\\n",
    "      -class $small_vocab"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "debug mode: 2\n",
      "train file: ../../eng_text/en_s2_train.txt\n",
      "valid file: ../../eng_text/en_s2_test.txt\n",
      "class size: 450\n",
      "Hidden layer size: 100\n",
      "BPTT: 0\n",
      "Rand seed: 1\n",
      "rnnlm file: en_s2\n",
      "Starting training using file ../../eng_text/en_s2_train.txt\n",
      "Restoring network from file to continue training...\n",
      "WARNING: number of classes exceeds vocabulary size!\n",
      "Iter:  12\tAlpha: 0.001563\t   TRAIN entropy: 5.8887    Words/sec: 11469.3   VALID entropy: 5.8379\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Training LM on subword units (larger vocab - eng_s3)\n",
    "\n",
    "# At what setting of rnnlm, we need the get the PP of baseline? \n",
    "# what is the use of class size\n",
    "# How to increase no. of iterations?\n",
    "\n",
    "#incr hidden -> better pp\n",
    "#incr bptt -> worse pp\n",
    "# if class < vocabsize -> worse pp\n",
    "#incr class -> better pp\n",
    "\n",
    "## May be need to simplify the corpus (in preprocessing)\n",
    "\n",
    "      # -bptt-block 1 \\\n",
    "!cd models/rnnlm/ \\\n",
    "    && ../../rnnlm/rnnlm \\\n",
    "    -train '../../eng_text/en_s3_train.txt' \\\n",
    "    -valid '../../eng_text/en_s3_test.txt' \\\n",
    "    -rnnlm en_s3 \\\n",
    "      -hidden 120 \\\n",
    "      -rand-seed 1 \\\n",
    "      -debug 2 \\\n",
    "      -bptt 0 \\\n",
    "      -class $large_vocab"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "debug mode: 2\n",
      "train file: ../../eng_text/en_s3_train.txt\n",
      "valid file: ../../eng_text/en_s3_test.txt\n",
      "class size: 2000\n",
      "Hidden layer size: 120\n",
      "BPTT: 0\n",
      "Rand seed: 1\n",
      "rnnlm file: en_s3\n",
      "Starting training using file ../../eng_text/en_s3_train.txt\n",
      "Restoring network from file to continue training...\n",
      "WARNING: number of classes exceeds vocabulary size!\n",
      "Iter:  13\tAlpha: 0.000781\t   TRAIN entropy: 7.0128    Words/sec: 2016.5   VALID entropy: 5.9636\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 4: Text Generation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "## 1. Character level granularity\n",
    "\n",
    "!cd models/rnnlm/ \\\n",
    "    && for i in 10 100 1000 10000 100000 1000000 10000000; do \\\n",
    "            ../../rnnlm/rnnlm \\\n",
    "            -rnnlm  en_s1\\\n",
    "            -gen $i \\\n",
    "            -debug 0 \\\n",
    "            >> \"../../eng_text/gen_en_s1/${i}.txt\"; \\\n",
    "       done"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "## 2. subword units (smaller vocab - en_s2)\n",
    "\n",
    "!cd models/rnnlm \\\n",
    "    && for i in 10 100 1000 10000 100000 1000000 10000000; do \\\n",
    "            ../../rnnlm/rnnlm \\\n",
    "            -rnnlm en_s2 \\\n",
    "            -gen $i \\\n",
    "            -debug 0 \\\n",
    "            >> \"../../eng_text/gen_en_s2/${i}.txt\"; \\\n",
    "       done"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## 3. subword units (larger vocab - en_s3)\n",
    "\n",
    "!cd models/rnnlm \\\n",
    "    && for i in 10 100 1000 10000 100000 1000000 10000000; do \\\n",
    "            ../../rnnlm/rnnlm \\\n",
    "            -rnnlm en_s3 \\\n",
    "            -gen $i \\\n",
    "            -debug 0 \\\n",
    "            >> \"../../eng_text/gen_en_s3/${i}.txt\"; \\\n",
    "       done"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "^C\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# back to original (human readable form) from subword units \n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_decode \\\n",
    "  --model=en_s1_train.model \\\n",
    "  --input_format=piece \\\n",
    "  < \"../../eng_text/gen_en_s1/100.txt\" \\\n",
    "  > \"../../eng_text/gen_en_s1/decod_100.txt\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# back to original (human readable form) from subword units \n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_decode \\\n",
    "  --model=en_s2_train.model \\\n",
    "  --input_format=piece \\\n",
    "  < \"../../eng_text/gen_en_s2/100.txt\" \\\n",
    "  > \"../../eng_text/gen_en_s2/decod_100.txt\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# back to original (human readable form) from subword units \n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_decode \\\n",
    "  --model=en_s3_train.model \\\n",
    "  --input_format=piece \\\n",
    "  < \"../../eng_text/gen_en_s3/100.txt\" \\\n",
    "  > \"../../eng_text/gen_en_s3/decod_100.txt\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Observation - quality of generated text\n",
    "*\n",
    "*\n",
    "*"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit ('snlp': virtualenvwrapper)"
  },
  "interpreter": {
   "hash": "aaaa3379fdd343e0cf653a09e7e2eeaa049f00680c9206d1a9bbb1ac6ef103f6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}