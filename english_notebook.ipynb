{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# from utils import preprocess, train_test_split_data\n",
    "from importlib import reload\n",
    "import os\n",
    "import utils\n",
    "utils = reload(utils)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 1: Data preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# sentencepiece package look for sentence hence linebreak needs to be preserved\n",
    "\n",
    "with open('data/alice_in_wonderland.txt') as f:\n",
    "    text = f.read()\n",
    "    prepro_text = utils.preprocess(text) # preprocessing text\n",
    "    train, test = utils.train_test_split_data(prepro_text, test_size=0.2) # split the data\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# saving the splitted corpus\n",
    "with open('eng_text/train_eng.txt', 'w') as f:\n",
    "    # f.write(str(train))\n",
    "    f.write('\\n'.join(train))\n",
    "\n",
    "with open('eng_text/test_eng.txt', 'w') as f:\n",
    "    # f.write(str(test)) \n",
    "    f.write('\\n'.join(test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comments/ideas\n",
    "* split is not randomized\n",
    "* more steps like lemmatization/stemming can be added in prepro\n",
    "* there is not much preprocessing needs to be done\n",
    "* may be some special characters/ punctuation can be removed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2: Subword Segmentation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Granularity: characters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# training model\n",
    "\n",
    "## CHANGE PATH TO SHIFT .model & .vocab in models/sentencepiece\n",
    "\n",
    "# total 72 different types of characters\n",
    "# coverage changes for non-english\n",
    "\n",
    "n_ch = 72\n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_train \\\n",
    "  --input='../../eng_text/train_eng.txt' \\\n",
    "  --model_prefix=en_s1_train \\\n",
    "  --vocab_size=$n_ch \\\n",
    "  --character_coverage=1.0 \\\n",
    "  --model_type=bpe\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../../eng_text/train_eng.txt\n",
      "  input_format: \n",
      "  model_prefix: en_s1_train\n",
      "  model_type: BPE\n",
      "  vocab_size: 72\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ../../eng_text/train_eng.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 2193 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=115724\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=69\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 2193 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 2193\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 4557\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: en_s1_train.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en_s1_train.vocab\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# segment the text (original)\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_encode \\\n",
    "  --model=en_s1_train.model \\\n",
    "  --output_format=piece \\\n",
    "  < '../../eng_text/train_eng.txt' \\\n",
    "  > '../../eng_text/en_s1_train.txt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# training model - test set\n",
    "\n",
    "## CHANGE PATH TO SHIFT .model & .vocab in models/sentencepiece\n",
    "\n",
    "# total 72 different types of characters\n",
    "# coverage changes for non-english\n",
    "\n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_train \\\n",
    "  --input='../../eng_text/test_eng.txt' \\\n",
    "  --model_prefix=en_s1_test \\\n",
    "  --vocab_size=$n_ch \\\n",
    "  --character_coverage=1.0 \\\n",
    "  --model_type=bpe\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../../eng_text/test_eng.txt\n",
      "  input_format: \n",
      "  model_prefix: en_s1_test\n",
      "  model_type: BPE\n",
      "  vocab_size: 72\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ../../eng_text/test_eng.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 533 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=26801\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=67\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 533 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 533\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 1656\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=813 min_freq=1\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: en_s1_test.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en_s1_test.vocab\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# segment the text (original) - test set\n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_encode \\\n",
    "  --model=en_s1_test.model \\\n",
    "  --output_format=piece \\\n",
    "  < '../../eng_text/test_eng.txt' \\\n",
    "  > '../../eng_text/en_s1_test.txt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Granularity: subword units (smaller vocabulary)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# training model\n",
    "\n",
    "# coverage changes for non-english\n",
    "# fine-tune vocab_size in range of 100-800 for best performance\n",
    "\n",
    "small_vocab = 450\n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_train \\\n",
    "  --input='../../eng_text/train_eng.txt' \\\n",
    "  --model_prefix=en_s2_train \\\n",
    "  --vocab_size=$small_vocab \\\n",
    "  --character_coverage=1.0 \\\n",
    "  --model_type=bpe\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../../eng_text/train_eng.txt\n",
      "  input_format: \n",
      "  model_prefix: en_s2_train\n",
      "  model_type: BPE\n",
      "  vocab_size: 450\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ../../eng_text/train_eng.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 2193 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=115724\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=69\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 2193 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 2193\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 4557\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3200 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=626 size=20 all=1259 active=1190 piece=▁c\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=423 size=40 all=1592 active=1523 piece=▁g\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=319 size=60 all=1912 active=1843 piece=▁was\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=216 size=80 all=2168 active=2099 piece=▁T\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=155 size=100 all=2443 active=2374 piece=ad\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=153 min_freq=7\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=117 size=120 all=2637 active=1167 piece=ill\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=98 size=140 all=2827 active=1357 piece=ge\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=85 size=160 all=3038 active=1568 piece=ab\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=78 size=180 all=3172 active=1702 piece=ere\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=66 size=200 all=3236 active=1766 piece=▁say\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=66 min_freq=7\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=59 size=220 all=3363 active=1126 piece=▁Qu\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=52 size=240 all=3459 active=1222 piece=ting\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=47 size=260 all=3585 active=1348 piece=atter\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=43 size=280 all=3705 active=1468 piece=▁now\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=39 size=300 all=3798 active=1561 piece=dd\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=39 min_freq=6\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=37 size=320 all=3869 active=1062 piece=▁\"\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=34 size=340 all=3920 active=1113 piece=ess\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32 size=360 all=3984 active=1177 piece=ER\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: en_s2_train.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en_s2_train.vocab\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# segment the text (original) -train\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_encode \\\n",
    "  --model=en_s2_train.model \\\n",
    "  --output_format=piece \\\n",
    "  < '../../eng_text/train_eng.txt' \\\n",
    "  > '../../eng_text/en_s2_train.txt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# training model - test set\n",
    "\n",
    "# coverage changes for non-english\n",
    "# fine-tune vocab_size in range of 100-800 for best performance\n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_train \\\n",
    "  --input='../../eng_text/test_eng.txt' \\\n",
    "  --model_prefix=en_s2_test \\\n",
    "  --vocab_size=$small_vocab \\\n",
    "  --character_coverage=1.0 \\\n",
    "  --model_type=bpe\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../../eng_text/test_eng.txt\n",
      "  input_format: \n",
      "  model_prefix: en_s2_test\n",
      "  model_type: BPE\n",
      "  vocab_size: 450\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ../../eng_text/test_eng.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 533 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=26801\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=67\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 533 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 533\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 1656\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=813 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=141 size=20 all=1015 active=948 piece=▁of\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=89 size=40 all=1260 active=1193 piece=or\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=68 size=60 all=1475 active=1408 piece=▁she\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=50 size=80 all=1662 active=1595 piece=▁was\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=40 size=100 all=1796 active=1729 piece=▁with\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=39 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28 size=120 all=1932 active=1136 piece=ry\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23 size=140 all=2031 active=1235 piece=ul\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20 size=160 all=2097 active=1301 piece=▁one\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17 size=180 all=2159 active=1363 piece=ph\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16 size=200 all=2193 active=1397 piece=ear\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=16 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15 size=220 all=2258 active=1055 piece=ting\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13 size=240 all=2321 active=1118 piece=up\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=260 all=2372 active=1169 piece=ame\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=280 all=2439 active=1236 piece=You\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=300 all=2490 active=1287 piece=▁over\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=320 all=2538 active=1048 piece=ther\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=340 all=2579 active=1089 piece=arch\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=360 all=2604 active=1114 piece=▁F\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=380 all=2621 active=1131 piece=▁next\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: en_s2_test.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en_s2_test.vocab\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# segment the text (original)\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_encode \\\n",
    "  --model=en_s2_test.model \\\n",
    "  --output_format=piece \\\n",
    "  < '../../eng_text/test_eng.txt' \\\n",
    "  > '../../eng_text/en_s2_test.txt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Granularity: subword units (larger vocabulary)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# training model\n",
    "\n",
    "# coverage changes for non-english\n",
    "# fine-tune vocab_size in range of 1500-3000 for best performance\n",
    "# training model\n",
    "\n",
    "# coverage changes for non-english\n",
    "# fine-tune vocab_size in range of 100-800 for best performance\n",
    "\n",
    "large_vocab = 2000\n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_train \\\n",
    "  --input='../../eng_text/train_eng.txt' \\\n",
    "  --model_prefix=en_s3_train \\\n",
    "  --vocab_size=$large_vocab \\\n",
    "  --character_coverage=1.0 \\\n",
    "  --model_type=bpe\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../../eng_text/train_eng.txt\n",
      "  input_format: \n",
      "  model_prefix: en_s3_train\n",
      "  model_type: BPE\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ../../eng_text/train_eng.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 2193 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=115724\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=69\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 2193 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 2193\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 4557\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3200 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=626 size=20 all=1259 active=1190 piece=▁c\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=423 size=40 all=1592 active=1523 piece=▁g\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=319 size=60 all=1912 active=1843 piece=▁was\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=216 size=80 all=2168 active=2099 piece=▁T\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=155 size=100 all=2443 active=2374 piece=ad\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=153 min_freq=7\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=117 size=120 all=2637 active=1167 piece=ill\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=98 size=140 all=2827 active=1357 piece=ge\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=85 size=160 all=3038 active=1568 piece=ab\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=78 size=180 all=3172 active=1702 piece=ere\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=66 size=200 all=3236 active=1766 piece=▁say\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=66 min_freq=7\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=59 size=220 all=3363 active=1126 piece=▁Qu\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=52 size=240 all=3459 active=1222 piece=ting\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=47 size=260 all=3585 active=1348 piece=atter\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=43 size=280 all=3705 active=1468 piece=▁now\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=39 size=300 all=3798 active=1561 piece=dd\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=39 min_freq=6\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=37 size=320 all=3869 active=1062 piece=▁\"\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=34 size=340 all=3920 active=1113 piece=ess\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32 size=360 all=3984 active=1177 piece=ER\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=30 size=380 all=4113 active=1306 piece=OU\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28 size=400 all=4209 active=1402 piece=HA\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=28 min_freq=6\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=27 size=420 all=4272 active=1058 piece=▁Dorm\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25 size=440 all=4299 active=1085 piece=ire\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24 size=460 all=4359 active=1145 piece=ation\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23 size=480 all=4423 active=1209 piece=▁than\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22 size=500 all=4448 active=1234 piece=▁garden\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=21 min_freq=5\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21 size=520 all=4524 active=1076 piece=▁make\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20 size=540 all=4567 active=1119 piece=▁sort\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19 size=560 all=4607 active=1159 piece=▁half\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18 size=580 all=4625 active=1177 piece=▁spea\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16 size=600 all=4674 active=1226 piece=How\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=16 min_freq=4\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16 size=620 all=4738 active=1065 piece=▁face\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15 size=640 all=4792 active=1119 piece=▁ear\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14 size=660 all=4843 active=1170 piece=dge\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14 size=680 all=4864 active=1191 piece=▁side\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13 size=700 all=4870 active=1197 piece=fe\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=13 min_freq=4\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13 size=720 all=4910 active=1039 piece=▁far\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13 size=740 all=4903 active=1032 piece=▁perhaps\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=760 all=4952 active=1081 piece=▁thr\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=780 all=4962 active=1091 piece=▁hedge\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=800 all=5016 active=1145 piece=outh\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11 min_freq=4\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=820 all=5040 active=1023 piece=▁tail\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=840 all=5030 active=1013 piece=PT\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=860 all=5053 active=1036 piece=ching\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=880 all=5070 active=1053 piece=HAPTER\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=900 all=5062 active=1045 piece=▁execution\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=920 all=5112 active=1049 piece=▁Oh\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=940 all=5120 active=1057 piece=▁hold\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=960 all=5123 active=1060 piece=▁hardly\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=980 all=5118 active=1055 piece=VE\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1000 all=5170 active=1107 piece=▁gu\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1020 all=5206 active=1034 piece=light\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1040 all=5205 active=1033 piece=▁ready\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1060 all=5195 active=1023 piece=▁minutes\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1080 all=5210 active=1038 piece=of\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1100 all=5272 active=1100 piece=▁ME\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1120 all=5296 active=1025 piece=iddle\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1140 all=5296 active=1025 piece=▁show\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1160 all=5294 active=1023 piece=▁bright\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1180 all=5283 active=1012 piece=▁generally\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=1200 all=5318 active=1047 piece=ret\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=1220 all=5343 active=1019 piece=ject\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=1240 all=5365 active=1041 piece=▁nur\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=1260 all=5382 active=1058 piece=▁hour\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=1280 all=5380 active=1056 piece=▁world\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=1300 all=5373 active=1049 piece=▁puzzled\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1320 all=5364 active=992 piece=ES\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1340 all=5401 active=1029 piece=oof\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1360 all=5416 active=1044 piece=▁cut\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1380 all=5424 active=1052 piece=erson\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1400 all=5427 active=1055 piece=▁fire\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=5 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1420 all=5428 active=1001 piece=iosity\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1440 all=5421 active=994 piece=▁animal\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1460 all=5410 active=983 piece=▁crowded\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=1480 all=5393 active=966 piece=▁interesting\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1500 all=5428 active=1001 piece=\"--\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1520 all=5449 active=1021 piece=iny\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1540 all=5467 active=1039 piece=arse\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1560 all=5498 active=1070 piece=rill\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1580 all=5505 active=1077 piece=▁esc\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1600 all=5515 active=1087 piece=Which\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1620 all=5524 active=1010 piece=▁behe\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1640 all=5519 active=1005 piece=▁shap\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1660 all=5516 active=1002 piece=▁bring\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1680 all=5502 active=988 piece=▁since\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1700 all=5498 active=984 piece=▁friend\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1720 all=5491 active=993 piece=▁between\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1740 all=5477 active=979 piece=▁puzzling\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=1760 all=5459 active=961 piece=▁difficulty\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1780 all=5475 active=977 piece=em\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1800 all=5497 active=999 piece=eal\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1820 all=5525 active=1023 piece=▁IN\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1840 all=5533 active=1031 piece=lled\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1860 all=5544 active=1042 piece=▁SHE\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1880 all=5545 active=1043 piece=▁sad\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1900 all=5551 active=1049 piece=ucked\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=1920 all=5543 active=992 piece=▁fear\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: en_s3_train.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en_s3_train.vocab\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# segment the text (original)\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_encode \\\n",
    "  --model=en_s3_train.model \\\n",
    "  --output_format=piece \\\n",
    "  < '../../eng_text/train_eng.txt' \\\n",
    "  > '../../eng_text/en_s3_train.txt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# training model - test set\n",
    "\n",
    "# coverage changes for non-english\n",
    "# fine-tune vocab_size in range of 1500-3000 for best performance\n",
    "# training model\n",
    "\n",
    "# coverage changes for non-english\n",
    "# fine-tune vocab_size in range of 100-800 for best performance\n",
    "\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_train \\\n",
    "  --input='../../eng_text/test_eng.txt' \\\n",
    "  --model_prefix=en_s3_test \\\n",
    "  --vocab_size=$large_vocab \\\n",
    "  --character_coverage=1.0 \\\n",
    "  --model_type=bpe\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../../eng_text/test_eng.txt\n",
      "  input_format: \n",
      "  model_prefix: en_s3_test\n",
      "  model_type: BPE\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ../../eng_text/test_eng.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 533 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=26801\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=67\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 533 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 533\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 1656\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=813 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=141 size=20 all=1015 active=948 piece=▁of\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=89 size=40 all=1260 active=1193 piece=or\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=68 size=60 all=1475 active=1408 piece=▁she\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=50 size=80 all=1662 active=1595 piece=▁was\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=40 size=100 all=1796 active=1729 piece=▁with\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=39 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28 size=120 all=1932 active=1136 piece=ry\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23 size=140 all=2031 active=1235 piece=ul\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20 size=160 all=2097 active=1301 piece=▁one\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17 size=180 all=2159 active=1363 piece=ph\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16 size=200 all=2193 active=1397 piece=ear\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=16 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15 size=220 all=2258 active=1055 piece=ting\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13 size=240 all=2321 active=1118 piece=up\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=260 all=2372 active=1169 piece=ame\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=280 all=2439 active=1236 piece=You\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=300 all=2490 active=1287 piece=▁over\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=320 all=2538 active=1048 piece=ther\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=340 all=2579 active=1089 piece=arch\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=360 all=2604 active=1114 piece=▁F\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=380 all=2621 active=1131 piece=▁next\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=400 all=2643 active=1153 piece=oll\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=420 all=2678 active=1030 piece=▁made\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=440 all=2708 active=1060 piece=she\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=460 all=2735 active=1087 piece=▁fin\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=480 all=2733 active=1085 piece=▁tarts\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=500 all=2753 active=1105 piece=cup\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=5 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=520 all=2786 active=1032 piece=▁we\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=540 all=2811 active=1057 piece=▁back\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=560 all=2800 active=1046 piece=▁juror\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=580 all=2795 active=1041 piece=LD\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=600 all=2834 active=1080 piece=old\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=620 all=2869 active=1029 piece=▁den\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=640 all=2875 active=1035 piece=▁conf\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=660 all=2869 active=1029 piece=▁eager\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=680 all=2861 active=1021 piece=▁turning\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=700 all=2863 active=1023 piece=bs\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=720 all=2882 active=1019 piece=ies\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=740 all=2901 active=1038 piece=▁im\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=760 all=2911 active=1048 piece=inut\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=780 all=2922 active=1059 piece=▁may\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=800 all=2933 active=1070 piece=▁Here\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=820 all=2923 active=991 piece=▁puzz\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=840 all=2919 active=987 piece=▁mouth\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=860 all=2913 active=981 piece=▁confus\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=880 all=2900 active=968 piece=▁strange\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=900 all=2885 active=953 piece=ID\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=920 all=2916 active=1029 piece=▁[\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=940 all=2925 active=1038 piece=eal\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=960 all=2944 active=1057 piece=sts\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=980 all=2948 active=1061 piece=▁en\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1000 all=2958 active=1071 piece=hind\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1020 all=2962 active=1004 piece=▁FIT\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1040 all=2961 active=1003 piece=▁has\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1060 all=2960 active=1002 piece=ardon\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1080 all=2968 active=1010 piece=wards\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1100 all=2957 active=999 piece=▁fact\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1120 all=2947 active=991 piece=▁note\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1140 all=2935 active=979 piece=HAPTER\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1160 all=2927 active=971 piece=▁grave\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1180 all=2916 active=960 piece=▁those\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1200 all=2903 active=947 piece=▁immedi\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1220 all=2888 active=985 piece=▁However\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1240 all=2868 active=965 piece=▁without\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2 size=1260 all=2852 active=949 piece=▁parchment\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1280 all=2836 active=933 piece=AS\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1300 all=2838 active=935 piece=RU\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1320 all=2847 active=1008 piece=me\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1340 all=2845 active=1006 piece=And\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1360 all=2840 active=1001 piece=Off\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1380 all=2835 active=996 piece=arm\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1400 all=2844 active=1005 piece=gar\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1 min_freq=0\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1420 all=2851 active=1007 piece=jur\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1440 all=2858 active=1014 piece=raw\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1460 all=2863 active=1019 piece=▁FA\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1480 all=2856 active=1012 piece=▁sl\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1500 all=2853 active=1009 piece=THER\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1 min_freq=0\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1520 all=2851 active=998 piece=ddle\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1540 all=2857 active=1004 piece=inch\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1560 all=2854 active=1001 piece=reen\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1580 all=2853 active=1000 piece=yard\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1600 all=2836 active=983 piece=▁WAS\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1 min_freq=0\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1620 all=2823 active=988 piece=▁fid\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1640 all=2817 active=982 piece=▁pun\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1660 all=2804 active=969 piece=Which\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1680 all=2805 active=970 piece=cover\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1700 all=2806 active=971 piece=illed\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1 min_freq=0\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1720 all=2806 active=1000 piece=rings\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1740 all=2799 active=993 piece=▁MILE\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1760 all=2782 active=976 piece=▁asse\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1780 all=2768 active=962 piece=▁fear\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1800 all=2753 active=947 piece=▁many\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1 min_freq=0\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1820 all=2739 active=987 piece=▁seen\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1840 all=2725 active=973 piece=▁tiny\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1860 all=2709 active=957 piece=Nearly\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1880 all=2701 active=949 piece=mitted\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1900 all=2693 active=941 piece=▁RETUR\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1 min_freq=0\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=1920 all=2677 active=984 piece=▁clapp\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: en_s3_test.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en_s3_test.vocab\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# segment the text (original)\n",
    "!cd models/sentencepiece/ \\\n",
    "  &&spm_encode \\\n",
    "  --model=en_s3_test.model \\\n",
    "  --output_format=piece \\\n",
    "  < '../../eng_text/test_eng.txt' \\\n",
    "  > '../../eng_text/en_s3_test.txt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Observation\n",
    "* Character - Almost every single character is segmented\n",
    "* Subword unit (smaller vacob) - The length of segmented subword is longer and many words are also considered as subwords\n",
    "* Subword unit (larger vocab) - Here, subwords are longer. Many words are themself segmented into single subwords. It can also be seen consistently that orignally longer words are broken into two or more segments.  \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 3: LM Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Training baseline LM (eng_s1)\n",
    "\n",
    "# At what setting of rnnlm, we need the get the PP of baseline? \n",
    "# what is the use of class size\n",
    "\n",
    "!cd models/rnnlm \\\n",
    "    && ../../rnnlm/rnnlm \\\n",
    "    -train '../../eng_text/en_s1_train.txt' \\\n",
    "    -valid '../../eng_text/en_s1_test.txt' \\\n",
    "    -rnnlm en_s1 \\\n",
    "      -hidden 40 \\\n",
    "      -rand-seed 1 \\\n",
    "      -debug 2 \\\n",
    "      -bptt 3 \\\n",
    "      -class $n_ch"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "debug mode: 2\n",
      "train file: ../../eng_text/en_s1_train.txt\n",
      "valid file: ../../eng_text/en_s1_test.txt\n",
      "class size: 72\n",
      "Hidden layer size: 40\n",
      "BPTT: 3\n",
      "Rand seed: 1\n",
      "rnnlm file: en_s1\n",
      "Starting training using file ../../eng_text/en_s1_train.txt\n",
      "Vocab size: 70\n",
      "Words in train file: 118604\n",
      "WARNING: number of classes exceeds vocabulary size!\n",
      "Iter:   0\tAlpha: 0.100000\t   TRAIN entropy: 3.1762    Words/sec: 120519.6   VALID entropy: 3.3980\n",
      "Iter:   1\tAlpha: 0.100000\t   TRAIN entropy: 2.7317    Words/sec: 120179.7   VALID entropy: 3.3017\n",
      "Iter:   2\tAlpha: 0.100000\t   TRAIN entropy: 2.6280    Words/sec: 117209.2   VALID entropy: 3.2969\n",
      "Iter:   3\tAlpha: 0.050000\t   TRAIN entropy: 2.5256    Words/sec: 120803.1   VALID entropy: 3.2101\n",
      "Iter:   4\tAlpha: 0.025000\t   TRAIN entropy: 2.4736    Words/sec: 118177.9   VALID entropy: 3.1691\n",
      "Iter:   5\tAlpha: 0.012500\t   TRAIN entropy: 2.4478    Words/sec: 116226.3   VALID entropy: 3.1410\n",
      "Iter:   6\tAlpha: 0.006250\t   TRAIN entropy: 2.4349    Words/sec: 118532.8   VALID entropy: 3.1216\n",
      "Iter:   7\tAlpha: 0.003125\t   TRAIN entropy: 2.4280    Words/sec: 114425.4   VALID entropy: 3.1080\n",
      "Iter:   8\tAlpha: 0.001563\t   TRAIN entropy: 2.4240    Words/sec: 113553.0   VALID entropy: 3.0992\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Training LM on subword units (smaller vocab - eng_s2)\n",
    "\n",
    "# At what setting of rnnlm, we need the get the PP of baseline? \n",
    "# what is the use of class size\n",
    "# How to increase no. of iterations?\n",
    "\n",
    "#incr hidden -> better pp\n",
    "#incr bptt -> worse pp\n",
    "# if class < vocabsize -> worse pp\n",
    "#incr class -> better pp\n",
    "\n",
    "## May be need to simplify the corpus (in preprocessing)\n",
    "\n",
    "      # -bptt-block 1 \\\n",
    "!cd models/rnnlm/ \\\n",
    "    && ../../rnnlm/rnnlm \\\n",
    "    -train '../../eng_text/en_s2_train.txt' \\\n",
    "    -valid '../../eng_text/en_s2_test.txt' \\\n",
    "    -rnnlm en_s2 \\\n",
    "      -hidden 100 \\\n",
    "      -rand-seed 1 \\\n",
    "      -debug 2 \\\n",
    "      -bptt 0 \\\n",
    "      -class $small_vocab"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "debug mode: 2\n",
      "train file: ../../eng_text/en_s2_train.txt\n",
      "valid file: ../../eng_text/en_s2_test.txt\n",
      "class size: 450\n",
      "Hidden layer size: 100\n",
      "BPTT: 0\n",
      "Rand seed: 1\n",
      "rnnlm file: eng_s2\n",
      "Starting training using file ../../eng_text/en_s2_train.txt\n",
      "Vocab size: 442\n",
      "Words in train file: 48838\n",
      "WARNING: number of classes exceeds vocabulary size!\n",
      "Iter:   0\tAlpha: 0.100000\t   TRAIN entropy: 7.5108    Words/sec: 11522.8   VALID entropy: 7.0572\n",
      "Iter:   1\tAlpha: 0.100000\t   TRAIN entropy: 6.7040    Words/sec: 12123.2   VALID entropy: 6.5983\n",
      "Iter:   2\tAlpha: 0.100000\t   TRAIN entropy: 6.0890    Words/sec: 12113.0   VALID entropy: 6.3793\n",
      "Iter:   3\tAlpha: 0.100000\t   TRAIN entropy: 5.6565    Words/sec: 11449.1   VALID entropy: 6.2852\n",
      "Iter:   4\tAlpha: 0.100000\t   TRAIN entropy: 5.3656    Words/sec: 11544.1   VALID entropy: 6.2402\n",
      "Iter:   5\tAlpha: 0.100000\t   TRAIN entropy: 5.1630    Words/sec: 11486.1   VALID entropy: 6.2321\n",
      "Iter:   6\tAlpha: 0.050000\t   TRAIN entropy: 4.9134    Words/sec: 11534.3   VALID entropy: 6.1312\n",
      "Iter:   7\tAlpha: 0.025000\t   TRAIN entropy: 4.7677    Words/sec: 11490.7   VALID entropy: 6.0420\n",
      "Iter:   8\tAlpha: 0.012500\t   TRAIN entropy: 4.6878    Words/sec: 12621.1   VALID entropy: 5.9746\n",
      "Iter:   9\tAlpha: 0.006250\t   TRAIN entropy: 4.6462    Words/sec: 12761.9   VALID entropy: 5.9316\n",
      "Iter:  10\tAlpha: 0.003125\t   TRAIN entropy: 4.6244    Words/sec: 12755.2   VALID entropy: 5.9066\n",
      "Iter:  11\tAlpha: 0.001563\t   TRAIN entropy: 4.6125    Words/sec: 12768.1   VALID entropy: 5.8935\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Training LM on subword units (larger vocab - eng_s3)\n",
    "\n",
    "# At what setting of rnnlm, we need the get the PP of baseline? \n",
    "# what is the use of class size\n",
    "# How to increase no. of iterations?\n",
    "\n",
    "#incr hidden -> better pp\n",
    "#incr bptt -> worse pp\n",
    "# if class < vocabsize -> worse pp\n",
    "#incr class -> better pp\n",
    "\n",
    "## May be need to simplify the corpus (in preprocessing)\n",
    "\n",
    "      # -bptt-block 1 \\\n",
    "!cd models/rnnlm/ \\\n",
    "    && ../../rnnlm/rnnlm \\\n",
    "    -train '../../eng_text/en_s3_train.txt' \\\n",
    "    -valid '../../eng_text/en_s3_test.txt' \\\n",
    "    -rnnlm en_s3 \\\n",
    "      -hidden 120 \\\n",
    "      -rand-seed 1 \\\n",
    "      -debug 2 \\\n",
    "      -bptt 0 \\\n",
    "      -class $large_vocab"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "debug mode: 2\n",
      "train file: ../../eng_text/en_s2_train.txt\n",
      "valid file: ../../eng_text/en_s2_test.txt\n",
      "class size: 450\n",
      "Hidden layer size: 100\n",
      "BPTT: 0\n",
      "Rand seed: 1\n",
      "rnnlm file: eng_s2\n",
      "Starting training using file ../../eng_text/en_s2_train.txt\n",
      "Vocab size: 442\n",
      "Words in train file: 48838\n",
      "WARNING: number of classes exceeds vocabulary size!\n",
      "Iter:   0\tAlpha: 0.100000\t   TRAIN entropy: 7.5108    Words/sec: 11522.8   VALID entropy: 7.0572\n",
      "Iter:   1\tAlpha: 0.100000\t   TRAIN entropy: 6.7040    Words/sec: 12123.2   VALID entropy: 6.5983\n",
      "Iter:   2\tAlpha: 0.100000\t   TRAIN entropy: 6.0890    Words/sec: 12113.0   VALID entropy: 6.3793\n",
      "Iter:   3\tAlpha: 0.100000\t   TRAIN entropy: 5.6565    Words/sec: 11449.1   VALID entropy: 6.2852\n",
      "Iter:   4\tAlpha: 0.100000\t   TRAIN entropy: 5.3656    Words/sec: 11544.1   VALID entropy: 6.2402\n",
      "Iter:   5\tAlpha: 0.100000\t   TRAIN entropy: 5.1630    Words/sec: 11486.1   VALID entropy: 6.2321\n",
      "Iter:   6\tAlpha: 0.050000\t   TRAIN entropy: 4.9134    Words/sec: 11534.3   VALID entropy: 6.1312\n",
      "Iter:   7\tAlpha: 0.025000\t   TRAIN entropy: 4.7677    Words/sec: 11490.7   VALID entropy: 6.0420\n",
      "Iter:   8\tAlpha: 0.012500\t   TRAIN entropy: 4.6878    Words/sec: 12621.1   VALID entropy: 5.9746\n",
      "Iter:   9\tAlpha: 0.006250\t   TRAIN entropy: 4.6462    Words/sec: 12761.9   VALID entropy: 5.9316\n",
      "Iter:  10\tAlpha: 0.003125\t   TRAIN entropy: 4.6244    Words/sec: 12755.2   VALID entropy: 5.9066\n",
      "Iter:  11\tAlpha: 0.001563\t   TRAIN entropy: 4.6125    Words/sec: 12768.1   VALID entropy: 5.8935\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 4: Text Generation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "## 1. Baseline\n",
    "\n",
    "!cd models/ \\\n",
    "    && for i in 10 100 1000 10000 100000 1000000 10000000; do \\\n",
    "            ../rnnlm/rnnlm \\\n",
    "            -rnnlm baseline \\\n",
    "            -gen $i \\\n",
    "            -debug 0 \\\n",
    "            >> \"../eng_text/baseline/${i}.txt\"; \\\n",
    "       done"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "## 2. subword units (smaller vocab - eng_s2)\n",
    "\n",
    "!cd models/ \\\n",
    "    && for i in 10 100 1000 10000 100000 1000000 10000000; do \\\n",
    "            ../rnnlm/rnnlm \\\n",
    "            -rnnlm eng_s2 \\\n",
    "            -gen $i \\\n",
    "            -debug 0 \\\n",
    "            >> \"../eng_text/eng_s2/${i}.txt\"; \\\n",
    "       done"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "^C\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "# back to original (human readable form) from subword units \n",
    "# !cd models/ \\\n",
    "!spm_decode \\\n",
    "  --model=en_s1.model \\\n",
    "  --input_format=piece \\\n",
    "  < \"eng_text/baseline/100.txt\" \\\n",
    "  > 'eng_text/baseline_100.txt'"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit ('snlp': virtualenvwrapper)"
  },
  "interpreter": {
   "hash": "aaaa3379fdd343e0cf653a09e7e2eeaa049f00680c9206d1a9bbb1ac6ef103f6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}